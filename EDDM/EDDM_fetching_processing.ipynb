{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import of required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "from traffic.core import Traffic, Flight\n",
    "from traffic.data import opensky, navaids, airports\n",
    "from typing import Union, List, Tuple\n",
    "from traffic.core.mixins import PointMixin\n",
    "from utils import helperfunctions as hf\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data fetching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "airport = \"EDDM\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paras\n",
    "folder_daily = f\"/mnt/beegfs/store/Projects_CRM/STAR_paper/{airport}/daily/\"\n",
    "date_range = pd.date_range(start='2023-01-01', end='2023-12-31', freq='D')\n",
    "\n",
    "# Fetching in daily packages\n",
    "for date in date_range:\n",
    "    path = f\"{folder_daily}{date.month}/\"\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    file = path + date.strftime('%Y-%m-%d')+\".parquet\"\n",
    "    if not os.path.exists(file):\n",
    "        print(f\"fetching {date}\")\n",
    "        try:\n",
    "            t = opensky.history(\n",
    "                start=date.strftime('%Y-%m-%d 00:00'),\n",
    "                stop=date.strftime('%Y-%m-%d 23:59'),\n",
    "                bounds=airports[airport].shape.buffer(1.5).bounds,\n",
    "            )\n",
    "            t.to_parquet(file)\n",
    "        except:\n",
    "            print(f\"failed to fetch {date}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing (clean invalid, assign id, only landings at airport, add landing runway)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduction to landing 04 in monthly packages-----------------------------------\n",
    "folder_list = os.listdir(folder_daily)\n",
    "# for each month\n",
    "for folder in folder_list:\n",
    "    # List all files in the folder\n",
    "    file_list = os.listdir(folder_daily + folder)\n",
    "    filepaths = [os.path.join(folder_daily + folder, file) for file in file_list]\n",
    "\n",
    "    # Merging to one trafic object\n",
    "    t = Traffic(\n",
    "        pd.concat(\n",
    "            [Traffic.from_file(file).data for file in tqdm(filepaths)],\n",
    "            ignore_index=True,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Cleaning\n",
    "    t = t.clean_invalid().assign_id().eval(desc=\"Cleaning\", max_workers=20)\n",
    "\n",
    "    # Reduce to landings at EDDM\n",
    "    t = (\n",
    "        t.iterate_lazy()\n",
    "        .pipe(hf.has_landing_at, \"EDDM\")\n",
    "        .eval(desc=\"landing at EDDM\", max_workers=20)\n",
    "    )\n",
    "\n",
    "    # Save\n",
    "    t.to_parquet(\n",
    "        f\"/mnt/beegfs/store/Projects_CRM/STAR_paper/{airport}/processed/monthly/landing_{folder}.parquet\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge monthly into one yearly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge all monthly packages to one yearly package------------------------------\n",
    "file_list = os.listdir(f\"/mnt/beegfs/store/Projects_CRM/STAR_paper/{airport}/processed/monthly/\")\n",
    "file_list = [file for file in file_list if file.startswith(\"landing_\")]\n",
    "filepaths = [\n",
    "    os.path.join(f\"/mnt/beegfs/store/Projects_CRM/STAR_paper/{airport}/processed/monthly\", file)\n",
    "    for file in file_list\n",
    "]\n",
    "t = Traffic(\n",
    "    pd.concat(\n",
    "        [Traffic.from_file(file).data for file in tqdm(filepaths)],\n",
    "        ignore_index=True,\n",
    "    )\n",
    ")\n",
    "t.to_parquet(f\"/mnt/beegfs/store/Projects_CRM/STAR_paper/{airport}/processed/landing_all.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add navaid info and crop before navaid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "t = Traffic.from_file(f\"/mnt/beegfs/store/Projects_CRM/STAR_paper/{airport}/processed/landing_all.parquet\")\n",
    "\n",
    "betos = navaids[\"BETOS\"]\n",
    "landu = navaids[\"LANDU\"]\n",
    "napsa = navaids[\"NAPSA\"]\n",
    "rokil = navaids[\"ROKIL\"]\n",
    "\n",
    "def add_navaid(flight: Flight) -> Union[Flight, None]:\n",
    "    \"\"\"\n",
    "    Add navaid information to the flight object for LIRF airport.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    flight : Flight\n",
    "        A flight object.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Flight\n",
    "        A flight object with navaid information in an additional column.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    if flight.aligned_on_navpoint(betos, 1, \"2T\", \"30s\", 20).has():\n",
    "        flight.data[\"navaid\"] = \"BETOS\"\n",
    "        flight = hf.crop_before_wp(flight, betos)\n",
    "        return flight\n",
    "    \n",
    "    if flight.aligned_on_navpoint(landu, 1, \"2T\", \"30s\", 20).has():\n",
    "        flight.data[\"navaid\"] = \"LANDU\"\n",
    "        flight = hf.crop_before_wp(flight, landu)\n",
    "        return flight \n",
    "    \n",
    "    if flight.aligned_on_navpoint(napsa, 1, \"2T\", \"30s\", 20).has():\n",
    "        flight.data[\"navaid\"] = \"NAPSA\"\n",
    "        flight = hf.crop_before_wp(flight, napsa)\n",
    "        return flight\n",
    "    \n",
    "    if flight.aligned_on_navpoint(rokil, 1, \"2T\", \"30s\", 20).has():\n",
    "        flight.data[\"navaid\"] = \"ROKIL\"\n",
    "        flight = hf.crop_before_wp(flight, rokil)\n",
    "        return flight\n",
    "        \n",
    "# add navaid information \n",
    "t = (\n",
    "    t.iterate_lazy()\n",
    "    .pipe(add_navaid)\n",
    "    .eval(desc=\"add navaid\", max_workers=20)\n",
    ")\n",
    "\n",
    "# save\n",
    "t.to_parquet(\n",
    "    f\"/mnt/beegfs/store/Projects_CRM/STAR_paper/{airport}/processed/landing_all_wp.parquet\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove GAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "t = Traffic.from_file(f\"/mnt/beegfs/store/Projects_CRM/STAR_paper/{airport}/processed/landing_all_wp.parquet\")\n",
    "\n",
    "# remove GAs\n",
    "t = (\n",
    "    t.iterate_lazy()\n",
    "    .pipe(hf.remove_ga, airport)\n",
    "    .eval(desc=\"removing GAs\", max_workers=20)\n",
    ")\n",
    "\n",
    "# save\n",
    "t.to_parquet(\n",
    "    f\"/mnt/beegfs/store/Projects_CRM/STAR_paper/{airport}/processed/landing_all_wp_ga.parquet\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crop after runway threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "t = Traffic.from_file(f\"/mnt/beegfs/store/Projects_CRM/STAR_paper/{airport}/processed/landing_all_wp_ga.parquet\")\n",
    "\n",
    "# remove GAs\n",
    "t = (\n",
    "    t.iterate_lazy()\n",
    "    .pipe(hf.crop_after_th, airport)\n",
    "    .eval(desc=\"removing GAs\", max_workers=20)\n",
    ")\n",
    "\n",
    "# save\n",
    "t.to_parquet(\n",
    "    f\"/mnt/beegfs/store/Projects_CRM/STAR_paper/{airport}/processed/landing_all_wp_ga_th.parquet\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "t = Traffic.from_file(f\"/mnt/beegfs/store/Projects_CRM/STAR_paper/{airport}/processed/landing_all_wp_ga_th.parquet\")\n",
    "\n",
    "# Filter\n",
    "t = t.filter().eval(desc=\"filtering\", max_workers=20)\n",
    "\n",
    "# save\n",
    "t.to_parquet(\n",
    "    f\"/mnt/beegfs/store/Projects_CRM/STAR_paper/{airport}/processed/landing_all_wp_ga_th_fr.parquet\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add cumulative distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "t = Traffic.from_file(f\"/mnt/beegfs/store/Projects_CRM/STAR_paper/{airport}/processed/landing_all_wp_ga_th_fr.parquet\")\n",
    "\n",
    "# Filter\n",
    "t = t.cumulative_distance().eval(desc=\"cumulative distance\", max_workers=20)\n",
    "\n",
    "# save\n",
    "t.to_parquet(\n",
    "    f\"/mnt/beegfs/store/Projects_CRM/STAR_paper/{airport}/processed/landing_all_wp_ga_th_fr_ds.parquet\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix to remove wrongly identified flights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "t = Traffic.from_file(f\"/mnt/beegfs/store/Projects_CRM/STAR_paper/{airport}/processed/landing_all_wp_ga_th_fr_ds.parquet\")\n",
    "\n",
    "# Remove flights with less than 20 nm\n",
    "ids = []\n",
    "for flight in tqdm(t):\n",
    "    if flight.data.cumdist.max() >= 20:\n",
    "        ids.append(flight.flight_id)\n",
    "t = t[ids]\n",
    "\n",
    "# save\n",
    "t.to_parquet(\n",
    "    f\"/mnt/beegfs/store/Projects_CRM/STAR_paper/{airport}/processed/landing_all_wp_ga_th_fr_ds.parquet\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "t = Traffic.from_file(f\"/mnt/beegfs/store/Projects_CRM/STAR_paper/{airport}/processed/landing_all_wp_ga_th_fr_ds.parquet\")\n",
    "\n",
    "# Initialize an empty list to collect data for each flight\n",
    "flight_data = []\n",
    "\n",
    "# Iterate through each flight and collect the relevant information\n",
    "for flight in tqdm(t):\n",
    "    id = flight.flight_id\n",
    "    typecode = flight.typecode\n",
    "    start = flight.start\n",
    "    stop = flight.stop\n",
    "    runway = flight.data.rwy.iloc[0]\n",
    "    navaid = flight.data.navaid.iloc[0]\n",
    "    distance = flight.data.cumdist.iloc[-1]\n",
    "    \n",
    "    # Append the flight data to the list as a tuple or list\n",
    "    flight_data.append([id, typecode, start, stop, runway, navaid, distance])\n",
    "\n",
    "# Create a DataFrame from the collected data\n",
    "df = pd.DataFrame(flight_data, columns=['id','typecode','start', 'stop', 'runway', 'navaid', 'distance'])\n",
    "\n",
    "# Save\n",
    "df.to_parquet(f\"/mnt/beegfs/store/Projects_CRM/STAR_paper/{airport}/processed/landing_df.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate subsamples to work locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Traffic.from_file(f\"/mnt/beegfs/store/Projects_CRM/STAR_paper/{airport}/processed/landing_all_wp_ga_th_fr_ds.parquet\")\n",
    "\n",
    "final_5000 = t.sample(5000)\n",
    "final_5000.to_parquet(f\"/mnt/beegfs/store/Projects_CRM/STAR_paper/{airport}/processed/sample_5000.parquet\")\n",
    "\n",
    "final_10000 = t.sample(10000)\n",
    "final_10000.to_parquet(f\"/mnt/beegfs/store/Projects_CRM/STAR_paper/{airport}/processed/sample_10000.parquet\")\n",
    "\n",
    "final_15000 = t.sample(15000)\n",
    "final_15000.to_parquet(f\"/mnt/beegfs/store/Projects_CRM/STAR_paper/{airport}/processed/sample_15000.parquet\")\n",
    "\n",
    "final_20000 = t.sample(20000)\n",
    "final_20000.to_parquet(f\"/mnt/beegfs/store/Projects_CRM/STAR_paper/{airport}/processed/sample_20000.parquet\")\n",
    "\n",
    "betos = t.query('navaid == \"BETOS\"')\n",
    "betos = betos.sample(min(1000, len(betos)))\n",
    "betos.to_parquet(f\"/mnt/beegfs/store/Projects_CRM/STAR_paper/{airport}/processed/betos.parquet\")\n",
    "\n",
    "landu = t.query('navaid == \"LANDU\"')\n",
    "landu = landu.sample(min(1000, len(landu)))\n",
    "landu.to_parquet(f\"/mnt/beegfs/store/Projects_CRM/STAR_paper/{airport}/processed/landu.parquet\")\n",
    "\n",
    "napsa = t.query('navaid == \"NAPSA\"')\n",
    "napsa = napsa.sample(min(1000, len(napsa)))\n",
    "napsa.to_parquet(f\"/mnt/beegfs/store/Projects_CRM/STAR_paper/{airport}/processed/napsa.parquet\")\n",
    "\n",
    "rokil = t.query('navaid == \"ROKIL\"')\n",
    "rokil = rokil.sample(min(1000, len(rokil)))\n",
    "rokil.to_parquet(f\"/mnt/beegfs/store/Projects_CRM/STAR_paper/{airport}/processed/rokil.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "t = Traffic.from_file(f\"/mnt/beegfs/store/Projects_CRM/STAR_paper/{airport}/processed/landing_all_wp_ga_th_fr_ds.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a single figure for the map\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add BETOS\n",
    "fig.add_trace(\n",
    "    go.Scattermapbox(\n",
    "        mode=\"markers+text\",\n",
    "        lat=[navaids[\"BETOS\"].latitude],\n",
    "        lon=[navaids[\"BETOS\"].longitude],\n",
    "        marker=dict(size=10, color=\"red\"),\n",
    "        text=[\"BETOS\"],\n",
    "        textposition=\"bottom left\",\n",
    "        textfont=dict(color=\"red\", size=25),\n",
    "        name=\"BETOS\",\n",
    "        showlegend=False,\n",
    "    )\n",
    ")\n",
    "for flight in t.query(\"navaid == 'BETOS'\").sample(30):\n",
    "    fig.add_trace(\n",
    "        go.Scattermapbox(\n",
    "            mode=\"lines\",\n",
    "            lat=flight.data[\"latitude\"],\n",
    "            lon=flight.data[\"longitude\"],\n",
    "            line=dict(width=1.5, color=\"#757ef3\"),\n",
    "            opacity=0.5,\n",
    "            name=\"Observed trajectories\",\n",
    "            showlegend=False,\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Add LANDU navaid\n",
    "fig.add_trace(\n",
    "    go.Scattermapbox(\n",
    "        mode=\"markers+text\",\n",
    "        lat=[navaids[\"LANDU\"].latitude],\n",
    "        lon=[navaids[\"LANDU\"].longitude],\n",
    "        marker=dict(size=10, color=\"red\"),\n",
    "        text=[\"LANDU\"],\n",
    "        textposition=\"top right\",\n",
    "        textfont=dict(color=\"red\", size=25),\n",
    "        name=\"LANDU\",\n",
    "        showlegend=False,\n",
    "    )\n",
    ")\n",
    "for flight in t.query(\"navaid == 'LANDU'\").sample(30):\n",
    "    fig.add_trace(\n",
    "        go.Scattermapbox(\n",
    "            mode=\"lines\",\n",
    "            lat=flight.data[\"latitude\"],\n",
    "            lon=flight.data[\"longitude\"],\n",
    "            line=dict(width=1.5, color=\"#757ef3\"),\n",
    "            opacity=0.5,\n",
    "            name=\"Observed trajectories\",\n",
    "            showlegend=False,\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Add NAPSA navaid\n",
    "fig.add_trace(\n",
    "    go.Scattermapbox(\n",
    "        mode=\"markers+text\",\n",
    "        lat=[navaids[\"NAPSA\"].latitude],\n",
    "        lon=[navaids[\"NAPSA\"].longitude],\n",
    "        marker=dict(size=10, color=\"red\"),\n",
    "        text=[\"NAPSA\"],\n",
    "        textposition=\"bottom right\",\n",
    "        textfont=dict(color=\"red\", size=25),\n",
    "        name=\"NAPSA\",\n",
    "        showlegend=False,\n",
    "    )\n",
    ")\n",
    "for flight in t.query(\"navaid == 'NAPSA'\").sample(30):\n",
    "    fig.add_trace(\n",
    "        go.Scattermapbox(\n",
    "            mode=\"lines\",\n",
    "            lat=flight.data[\"latitude\"],\n",
    "            lon=flight.data[\"longitude\"],\n",
    "            line=dict(width=1.5, color=\"#757ef3\"),\n",
    "            opacity=0.5,\n",
    "            name=\"Observed trajectories\",\n",
    "            showlegend=False,\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Add ROKIL navaid\n",
    "fig.add_trace(\n",
    "    go.Scattermapbox(\n",
    "        mode=\"markers+text\",\n",
    "        lat=[navaids[\"ROKIL\"].latitude],\n",
    "        lon=[navaids[\"ROKIL\"].longitude],\n",
    "        marker=dict(size=10, color=\"red\"),\n",
    "        text=[\"ROKIL\"],\n",
    "        textposition=\"top left\",\n",
    "        textfont=dict(color=\"red\", size=25),\n",
    "        name=\"ROKIL\",\n",
    "        showlegend=False,\n",
    "    )\n",
    ")\n",
    "for flight in t.query(\"navaid == 'ROKIL'\").sample(30):\n",
    "    fig.add_trace(\n",
    "        go.Scattermapbox(\n",
    "            mode=\"lines\",\n",
    "            lat=flight.data[\"latitude\"],\n",
    "            lon=flight.data[\"longitude\"],\n",
    "            line=dict(width=1.5, color=\"#757ef3\"),\n",
    "            opacity=0.5,\n",
    "            name=\"Observed trajectories\",\n",
    "            showlegend=False,\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Update layout for the map\n",
    "fig.update_layout(\n",
    "    width=1000,\n",
    "    height=1000,\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    "    mapbox=dict(\n",
    "        style=\"carto-positron\",\n",
    "        zoom=7.5,\n",
    "        center=dict(\n",
    "            lat=48.35387713470083,\n",
    "            lon=11.792605119315825,\n",
    "        ),\n",
    "    ),\n",
    "    legend=dict(\n",
    "        x=0.65,\n",
    "        y=0.97,\n",
    "        traceorder=\"normal\",\n",
    "        font=dict(size=25),\n",
    "        bgcolor=\"rgba(255, 255, 255, 0.7)\",\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Show the figure\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Poetry via SLURM STAR",
   "language": "python",
   "name": "jupyter-eg-kernel-slurm-py39-poetry-1i3hri4hc"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
