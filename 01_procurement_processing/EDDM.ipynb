{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import of required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "from traffic.core import Traffic, Flight\n",
    "from traffic.data import opensky, navaids, airports\n",
    "from typing import Union\n",
    "from utils import helperfunctions as hf\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "airport = \"EDDM\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data fetching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paras\n",
    "folder_daily = f\"/mnt/beegfs/store/Projects_CRM/STAR_paper/{airport}/daily/\"\n",
    "date_range = pd.date_range(start='2023-01-01', end='2023-12-31', freq='D')\n",
    "\n",
    "# Fetching in daily packages\n",
    "for date in date_range:\n",
    "    path = f\"{folder_daily}{date.month}/\"\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    file = path + date.strftime('%Y-%m-%d')+\".parquet\"\n",
    "    if not os.path.exists(file):\n",
    "        print(f\"fetching {date}\")\n",
    "        try:\n",
    "            t = opensky.history(\n",
    "                start=date.strftime('%Y-%m-%d 00:00'),\n",
    "                stop=date.strftime('%Y-%m-%d 23:59'),\n",
    "                bounds=airports[airport].shape.buffer(1.5).bounds,\n",
    "            )\n",
    "            t.to_parquet(file)\n",
    "        except:\n",
    "            print(f\"failed to fetch {date}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing (clean invalid, assign id, only landings at airport, add landing runway)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduction to landing 04 in monthly packages-----------------------------------\n",
    "folder_list = os.listdir(folder_daily)\n",
    "# for each month\n",
    "for folder in folder_list:\n",
    "    # List all files in the folder\n",
    "    file_list = os.listdir(folder_daily + folder)\n",
    "    filepaths = [os.path.join(folder_daily + folder, file) for file in file_list]\n",
    "\n",
    "    # Merging to one trafic object\n",
    "    t = Traffic(\n",
    "        pd.concat(\n",
    "            [Traffic.from_file(file).data for file in tqdm(filepaths)],\n",
    "            ignore_index=True,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Cleaning\n",
    "    t = t.clean_invalid().assign_id().eval(desc=\"Cleaning\", max_workers=20)\n",
    "\n",
    "    # Reduce to landings at EDDM\n",
    "    t = (\n",
    "        t.iterate_lazy()\n",
    "        .pipe(hf.has_landing_at, \"EDDM\")\n",
    "        .eval(desc=\"landing at EDDM\", max_workers=20)\n",
    "    )\n",
    "\n",
    "    # Save\n",
    "    t.to_parquet(\n",
    "        f\"/mnt/beegfs/store/Projects_CRM/STAR_paper/{airport}/processed/monthly/landing_{folder}.parquet\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge monthly into one yearly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge all monthly packages to one yearly package------------------------------\n",
    "file_list = os.listdir(f\"/mnt/beegfs/store/Projects_CRM/STAR_paper/{airport}/processed/monthly/\")\n",
    "file_list = [file for file in file_list if file.startswith(\"landing_\")]\n",
    "filepaths = [\n",
    "    os.path.join(f\"/mnt/beegfs/store/Projects_CRM/STAR_paper/{airport}/processed/monthly\", file)\n",
    "    for file in file_list\n",
    "]\n",
    "t = Traffic(\n",
    "    pd.concat(\n",
    "        [Traffic.from_file(file).data for file in tqdm(filepaths)],\n",
    "        ignore_index=True,\n",
    "    )\n",
    ")\n",
    "t.to_parquet(f\"/mnt/beegfs/store/Projects_CRM/STAR_paper/{airport}/processed/landing_all.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add star info and crop before navaid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "t = Traffic.from_file(f\"/mnt/beegfs/store/Projects_CRM/STAR_paper/{airport}/processed/landing_all.parquet\")\n",
    "\n",
    "betos = navaids[\"BETOS\"]\n",
    "landu = navaids[\"LANDU\"]\n",
    "napsa = navaids[\"NAPSA\"]\n",
    "rokil = navaids[\"ROKIL\"]\n",
    "\n",
    "def add_star(flight: Flight) -> Union[Flight, None]:\n",
    "    \"\"\"\n",
    "    Add star information to the flight object for LIRF airport.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    flight : Flight\n",
    "        A flight object.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Flight\n",
    "        A flight object with star information in an additional column.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    if flight.aligned_on_navpoint(betos, 1, \"2T\", \"30s\", 20).has():\n",
    "        if flight.data[\"rwy\"].iloc[0] in [\"08L\", \"08R\"]:\n",
    "            flight.data[\"star\"] = \"BETO1A\"\n",
    "            flight = hf.crop_before_wp(flight, betos)\n",
    "            return flight\n",
    "    \n",
    "    if flight.aligned_on_navpoint(landu, 1, \"2T\", \"30s\", 20).has():\n",
    "            if flight.data[\"rwy\"].iloc[0] in [\"26L\", \"26R\"]:\n",
    "                flight.data[\"star\"] = \"LAND1B\"\n",
    "                flight = hf.crop_before_wp(flight, landu)\n",
    "                return flight \n",
    "    \n",
    "    if flight.aligned_on_navpoint(napsa, 1, \"2T\", \"30s\", 20).has():\n",
    "        if flight.data[\"rwy\"].iloc[0] in [\"26L\", \"26R\"]:\n",
    "            flight.data[\"star\"] = \"NAPS1B\"\n",
    "            flight = hf.crop_before_wp(flight, napsa)\n",
    "            return flight\n",
    "    \n",
    "    if flight.aligned_on_navpoint(rokil, 1, \"2T\", \"30s\", 20).has():\n",
    "        if flight.data[\"rwy\"].iloc[0] in [\"08L\", \"08R\"]:\n",
    "            flight.data[\"star\"] = \"ROKI1A\"\n",
    "            flight = hf.crop_before_wp(flight, rokil)\n",
    "            return flight\n",
    "        \n",
    "# add navaid information \n",
    "t = (\n",
    "    t.iterate_lazy()\n",
    "    .pipe(add_star)\n",
    "    .eval(desc=\"add star\", max_workers=20)\n",
    ")\n",
    "\n",
    "# save\n",
    "t.to_parquet(\n",
    "    f\"/mnt/beegfs/store/Projects_CRM/STAR_paper/{airport}/processed/landing_all_wp.parquet\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove GAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "t = Traffic.from_file(f\"/mnt/beegfs/store/Projects_CRM/STAR_paper/{airport}/processed/landing_all_wp.parquet\")\n",
    "\n",
    "# remove GAs\n",
    "t = (\n",
    "    t.iterate_lazy()\n",
    "    .pipe(hf.remove_ga, airport)\n",
    "    .eval(desc=\"removing GAs\", max_workers=20)\n",
    ")\n",
    "\n",
    "# save\n",
    "t.to_parquet(\n",
    "    f\"/mnt/beegfs/store/Projects_CRM/STAR_paper/{airport}/processed/landing_all_wp_ga.parquet\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crop after runway threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "t = Traffic.from_file(f\"/mnt/beegfs/store/Projects_CRM/STAR_paper/{airport}/processed/landing_all_wp_ga.parquet\")\n",
    "\n",
    "# remove GAs\n",
    "t = (\n",
    "    t.iterate_lazy()\n",
    "    .pipe(hf.crop_after_th, airport)\n",
    "    .eval(desc=\"removing GAs\", max_workers=20)\n",
    ")\n",
    "\n",
    "# save\n",
    "t.to_parquet(\n",
    "    f\"/mnt/beegfs/store/Projects_CRM/STAR_paper/{airport}/processed/landing_all_wp_ga_th.parquet\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "t = Traffic.from_file(f\"/mnt/beegfs/store/Projects_CRM/STAR_paper/{airport}/processed/landing_all_wp_ga_th.parquet\")\n",
    "\n",
    "# Filter\n",
    "t = t.filter().eval(desc=\"filtering\", max_workers=20)\n",
    "\n",
    "# save\n",
    "t.to_parquet(\n",
    "    f\"/mnt/beegfs/store/Projects_CRM/STAR_paper/{airport}/processed/landing_all_wp_ga_th_fr.parquet\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add cumulative distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "t = Traffic.from_file(f\"/mnt/beegfs/store/Projects_CRM/STAR_paper/{airport}/processed/landing_all_wp_ga_th_fr.parquet\")\n",
    "\n",
    "# Filter\n",
    "t = t.cumulative_distance().eval(desc=\"cumulative distance\", max_workers=20)\n",
    "\n",
    "# save\n",
    "t.to_parquet(\n",
    "    f\"/mnt/beegfs/store/Projects_CRM/STAR_paper/{airport}/processed/landing_full.parquet\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix to remove wrongly identified flights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "t = Traffic.from_file(f\"/mnt/beegfs/store/Projects_CRM/STAR_paper/{airport}/processed/landing_full.parquet\")\n",
    "\n",
    "# Remove flights with less than 20 nm\n",
    "ids = []\n",
    "for flight in tqdm(t):\n",
    "    if flight.data.cumdist.max() >= 20:\n",
    "        ids.append(flight.flight_id)\n",
    "t = t[ids]\n",
    "\n",
    "# save\n",
    "t.to_parquet(\n",
    "    f\"/mnt/beegfs/store/Projects_CRM/STAR_paper/{airport}/processed/landing_full.parquet\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "t = Traffic.from_file(f\"/mnt/beegfs/store/Projects_CRM/STAR_paper/{airport}/processed/landing_full.parquet\")\n",
    "\n",
    "# Initialize an empty list to collect data for each flight\n",
    "flight_data = []\n",
    "\n",
    "# Iterate through each flight and collect the relevant information\n",
    "for flight in tqdm(t):\n",
    "    id = flight.flight_id\n",
    "    typecode = flight.typecode\n",
    "    start = flight.start\n",
    "    stop = flight.stop\n",
    "    runway = flight.data.rwy.iloc[0]\n",
    "    star = flight.data.star.iloc[0]\n",
    "    distance = flight.data.cumdist.iloc[-1]\n",
    "    \n",
    "    # Append the flight data to the list as a tuple or list\n",
    "    flight_data.append([id, typecode, start, stop, runway, star, distance])\n",
    "\n",
    "# Create a DataFrame from the collected data\n",
    "df = pd.DataFrame(flight_data, columns=['id','typecode','start', 'stop', 'runway', 'star', 'distance'])\n",
    "\n",
    "# Save\n",
    "df.to_parquet(f\"/mnt/beegfs/store/Projects_CRM/STAR_paper/{airport}/processed/landing_df.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate subsamples for visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Traffic.from_file(f\"/mnt/beegfs/store/Projects_CRM/STAR_paper/{airport}/processed/landing_full.parquet\")\n",
    "\n",
    "sample_2500 = t.sample(2500)\n",
    "sample_2500.to_parquet(f\"/mnt/beegfs/store/Projects_CRM/STAR_paper/{airport}/processed/sample_2500.parquet\")\n",
    "\n",
    "sample_5000 = t.sample(5000)\n",
    "sample_5000.to_parquet(f\"/mnt/beegfs/store/Projects_CRM/STAR_paper/{airport}/processed/sample_5000.parquet\")\n",
    "\n",
    "sample_10000 = t.sample(10000)\n",
    "sample_10000.to_parquet(f\"/mnt/beegfs/store/Projects_CRM/STAR_paper/{airport}/processed/sample_10000.parquet\")\n",
    "\n",
    "betos = t.query('star == \"BETO1A\"')\n",
    "betos = betos.sample(min(1000, len(betos)))\n",
    "betos.to_parquet(f\"/mnt/beegfs/store/Projects_CRM/STAR_paper/{airport}/processed/betos1a.parquet\")\n",
    "\n",
    "landu = t.query('star == \"LAND1B\"')\n",
    "landu = landu.sample(min(1000, len(landu)))\n",
    "landu.to_parquet(f\"/mnt/beegfs/store/Projects_CRM/STAR_paper/{airport}/processed/landu1b.parquet\")\n",
    "\n",
    "napsa = t.query('star == \"NAPS1B\"')\n",
    "napsa = napsa.sample(min(1000, len(napsa)))\n",
    "napsa.to_parquet(f\"/mnt/beegfs/store/Projects_CRM/STAR_paper/{airport}/processed/napsa1b.parquet\")\n",
    "\n",
    "rokil = t.query('star == \"ROKI1A\"')\n",
    "rokil = rokil.sample(min(1000, len(rokil)))\n",
    "rokil.to_parquet(f\"/mnt/beegfs/store/Projects_CRM/STAR_paper/{airport}/processed/rokil1a.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "t = Traffic.from_file(f\"/home/krum/git/STAR_shortcut_OSN_paper/data/EDDM/rokil1a.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a single figure for the map\n",
    "fig = go.Figure()\n",
    "\n",
    "for flight in t.sample(50):\n",
    "    fig.add_trace(\n",
    "        go.Scattermapbox(\n",
    "            mode=\"lines\",\n",
    "            lat=flight.data[\"latitude\"],\n",
    "            lon=flight.data[\"longitude\"],\n",
    "            line=dict(width=1.5, color=\"#757ef3\"),\n",
    "            opacity=0.5,\n",
    "            name=\"Observed trajectories\",\n",
    "            showlegend=False,\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Add BETOS\n",
    "fig.add_trace(\n",
    "    go.Scattermapbox(\n",
    "        mode=\"markers+text\",\n",
    "        lat=[navaids[\"BETOS\"].latitude],\n",
    "        lon=[navaids[\"BETOS\"].longitude],\n",
    "        marker=dict(size=10, color=\"red\"),\n",
    "        text=[\"BETOS\"],\n",
    "        textposition=\"bottom left\",\n",
    "        textfont=dict(color=\"red\", size=25),\n",
    "        name=\"BETOS\",\n",
    "        showlegend=False,\n",
    "    )\n",
    ")\n",
    "\n",
    "# Add LANDU navaid\n",
    "fig.add_trace(\n",
    "    go.Scattermapbox(\n",
    "        mode=\"markers+text\",\n",
    "        lat=[navaids[\"LANDU\"].latitude],\n",
    "        lon=[navaids[\"LANDU\"].longitude],\n",
    "        marker=dict(size=10, color=\"red\"),\n",
    "        text=[\"LANDU\"],\n",
    "        textposition=\"top right\",\n",
    "        textfont=dict(color=\"red\", size=25),\n",
    "        name=\"LANDU\",\n",
    "        showlegend=False,\n",
    "    )\n",
    ")\n",
    "\n",
    "# Add NAPSA navaid\n",
    "fig.add_trace(\n",
    "    go.Scattermapbox(\n",
    "        mode=\"markers+text\",\n",
    "        lat=[navaids[\"NAPSA\"].latitude],\n",
    "        lon=[navaids[\"NAPSA\"].longitude],\n",
    "        marker=dict(size=10, color=\"red\"),\n",
    "        text=[\"NAPSA\"],\n",
    "        textposition=\"bottom right\",\n",
    "        textfont=dict(color=\"red\", size=25),\n",
    "        name=\"NAPSA\",\n",
    "        showlegend=False,\n",
    "    )\n",
    ")\n",
    "\n",
    "# Add ROKIL navaid\n",
    "fig.add_trace(\n",
    "    go.Scattermapbox(\n",
    "        mode=\"markers+text\",\n",
    "        lat=[navaids[\"ROKIL\"].latitude],\n",
    "        lon=[navaids[\"ROKIL\"].longitude],\n",
    "        marker=dict(size=10, color=\"red\"),\n",
    "        text=[\"ROKIL\"],\n",
    "        textposition=\"top left\",\n",
    "        textfont=dict(color=\"red\", size=25),\n",
    "        name=\"ROKIL\",\n",
    "        showlegend=False,\n",
    "    )\n",
    ")\n",
    "\n",
    "# Update layout for the map\n",
    "fig.update_layout(\n",
    "    width=1000,\n",
    "    height=1000,\n",
    "    margin=dict(l=0, r=0, t=0, b=0),\n",
    "    mapbox=dict(\n",
    "        style=\"carto-positron\",\n",
    "        zoom=7.5,\n",
    "        center=dict(\n",
    "            lat=48.35387713470083,\n",
    "            lon=11.792605119315825,\n",
    "        ),\n",
    "    ),\n",
    "    legend=dict(\n",
    "        x=0.65,\n",
    "        y=0.97,\n",
    "        traceorder=\"normal\",\n",
    "        font=dict(size=25),\n",
    "        bgcolor=\"rgba(255, 255, 255, 0.7)\",\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Show the figure\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
